{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercice we are going to run an exploratory analysis of Olist datasets. First download all datasets from Kaggle here - https://www.kaggle.com/olistbr/brazilian-ecommerce/download (120Mb). \n",
    "\n",
    "Your directory should look like the following: \n",
    "\n",
    "\n",
    "```\n",
    "|.\n",
    "    ├── data\n",
    "        ├── csv\n",
    "    |       ├── product_category_name_translation.csv\n",
    "    |       ├── olist_sellers_dataset.csv\n",
    "    |       ├── olist_products_dataset.csv\n",
    "    |       ├── olist_orders_dataset.csv\n",
    "    |       ├── olist_order_reviews_dataset.csv\n",
    "    |       ├── olist_order_payments_dataset.csv\n",
    "    |       ├── olist_order_items_dataset.csv\n",
    "    |       ├── olist_geolocation_dataset.csv\n",
    "    |       ├── olist_customers_dataset.csv \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load all dataset in a dictionary named data where each key is the name of the csv file.\n",
    "- Run an exploratory analysis for the list of datasets below. Use [pandas-profiling](https://github.com/pandas-profiling/pandas-profiling) to output one HTML output per dataset under a `report` folder: \n",
    "\n",
    "```python\n",
    "['olist_orders_dataset', 'olist_products_dataset', 'olist_customers_dataset', 'olist_order_reviews_dataset', 'olist_order_items_dataset']\n",
    "```\n",
    "- Which columns have missing data? Which columns should be converted as datetime? \n",
    "- Perform a merge to obtain a matching table between `customer_id`, `customer_unique_id`, `order_id`, `product_id`, `seller_id` and export the obtained DataFrame to the `data` folder as `matching_table.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access all files in data directory\n",
    "# Hint: use the os library to navigate files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import each file as separate (key,values) pair of a single data dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Run an exploratory analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run an exploratory analysis for the list of datasets below. Use [pandas-profiling](https://github.com/pandas-profiling/pandas-profiling) to output one HTML output per dataset under a `report` folder. You can limit your analysis to those tables to save computing time:\n",
    "\n",
    "```python\n",
    "['olist_orders_dataset', 'olist_products_dataset', 'olist_customers_dataset', 'olist_order_reviews_dataset', 'olist_order_items_dataset']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Analyze reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which columns have missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why are some rows of the column `order_delivered_customer_date` null?\n",
    "# --> How would you filter the `order` dataset moving forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are dates in the right format? You may list here columns that should be converted to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Code your logic in olist/data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge: within the `olist/data.py` file, implement two methods:\n",
    "- `get_data()`: that will return all data as a dictionnary where each key contains each DataFrame\n",
    "- `get_matching_table()`: that will return a DataFrame with the following columns: `customer_id`, `customer_unique_id`, `order_id`, `product_id`, `seller_id`. Only return data for orders that are `delivered`.\n",
    "- Make sure you can import and inspect data from a notebook, by running:\n",
    "\n",
    "```python\n",
    "from olist.data import Olist\n",
    "olist = Olist()\n",
    "data = olist.get_data()\n",
    "matching_table = olist.get_matching_table()\n",
    "```\n",
    "\n",
    "- **Single source of truth**: Publish one working version of your data.py code to your team repo with git. This code will be shared and by everyone throughout the week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_matching_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the cardinality of each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carefully merge DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the cardinality of the final DataFrame. It should match the highest one. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
